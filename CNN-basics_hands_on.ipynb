{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lrsec3YjNTv"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ly28CADwjQsl"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRFGaGxUjTcZ"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21ysBv9sjYR5"
      },
      "outputs": [],
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lR_vE1hbjeBZ"
      },
      "outputs": [],
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAPLCh72jgPM",
        "outputId": "9c494437-aeed-492f-836b-a88460c7f9c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIYJp1SwjjmN"
      },
      "outputs": [],
      "source": [
        "! kaggle datasets list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2yYvROLjxQT"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d tongpython/cat-and-dog"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LEMIi-Fj8Ed"
      },
      "outputs": [],
      "source": [
        "!unzip cat-and-dog.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JRqIQ6_kES-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "from shutil import copyfile\n",
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import math\n",
        "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "#from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvSpp9LTkSFw"
      },
      "outputs": [],
      "source": [
        "train_dir = '/content/training_set/training_set/'\n",
        "test_dir = '/content/test_set/test_set/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXuqGFR-kgK0"
      },
      "outputs": [],
      "source": [
        "Image.open('/content/training_set/training_set/cats/cat.1.jpg').resize((300, 300))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjb0ks_JlKyl"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "img_height, img_width = 224, 224\n",
        "input_shape = (img_height, img_width, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rx6oiTJclW-j"
      },
      "outputs": [],
      "source": [
        "random_seed = np.random.seed(1142)\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    validation_split= 0.20,\n",
        "    zoom_range=0.2,\n",
        "    shear_range=0.2)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    seed = random_seed,\n",
        "    shuffle = False,\n",
        "    subset = 'training',\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    seed = random_seed,\n",
        "    shuffle = False,\n",
        "    subset = 'validation',\n",
        "    class_mode='binary')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    seed = random_seed,\n",
        "    shuffle = False,\n",
        "    class_mode='binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eow7ZSLsluaO"
      },
      "outputs": [],
      "source": [
        "nb_train_samples = len(train_generator.filenames)\n",
        "nb_validation_samples = len(validation_generator.filenames)\n",
        "nb_test_samples = len(test_generator.filenames)\n",
        "\n",
        "\n",
        "num_classes = len(train_generator.class_indices)\n",
        "\n",
        "print(\"nb_train_samples:\", nb_train_samples)\n",
        "print(\"nb_validation_samples:\", nb_validation_samples)\n",
        "print(\"nb_test_samples:\", nb_test_samples)\n",
        "print(\"\\n num_classes:\", num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0V2Ahf1-luf"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "plt.bar([\"train_generator\", \"validation_generator\", \"test_generator\"], [nb_train_samples, nb_validation_samples, nb_test_samples], color=[\"maroon\", \"cyan\", \"seagreen\"], width=0.4)\n",
        "plt.xlabel(\"Data\")\n",
        "plt.ylabel(\"Numbers\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BMSy7tgjZC7"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(filters=32, kernel_size=(3,3), padding='Same', activation='relu', input_shape=(img_height, img_width, 3)))\n",
        "model.add(MaxPool2D(pool_size=(2,2), strides=2))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), padding='Same', activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2), strides=2))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(200, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwsKWOzRmqcO"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "plot_model(model, show_shapes = True,expand_nested = True,dpi = 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KM-lfsMImqzF"
      },
      "outputs": [],
      "source": [
        "r= model.fit_generator(train_generator,\n",
        "             epochs=5,\n",
        "             verbose=1,\n",
        "             validation_data=validation_generator)                                                          "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Nce-dRjm4eJ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.style.use(\"seaborn-ticks\")\n",
        "\n",
        "plt.plot(r.history['accuracy'])\n",
        "plt.plot(r.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training Acc', 'Test Acc'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(r.history['loss'])\n",
        "plt.plot(r.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training Loss', 'Test Loss'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_whT1hGyq6h6"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "print(\"==============TEST RESULTS============\")\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False) \n",
        "test_labels = test_generator.classes\n",
        "test_labels = to_categorical(test_labels, num_classes=num_classes)\n",
        "y_true = [i.argmax() for i in test_labels]\n",
        "\n",
        "predictions = model.predict(test_generator, verbose=1)\n",
        "yPredictions = np.argmax(predictions, axis=1)\n",
        "true_classes = test_generator.classes\n",
        "confusion_mtx = confusion_matrix(true_classes, yPredictions) \n",
        "y_pred_probabilities=yPredictions\n",
        "classnames=[]\n",
        "for classname in test_generator.class_indices:\n",
        "    classnames.append(classname)\n",
        "\n",
        "target_names = classnames\n",
        "print(classification_report(true_classes, yPredictions, target_names=target_names))\n",
        "\n",
        "print('roc_auc_score = ' + str(roc_auc_score( true_classes, yPredictions)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKcmm9q9yttQ"
      },
      "outputs": [],
      "source": [
        "from matplotlib import cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYLysa2B3pOy"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "test_labels = test_generator.classes\n",
        "test_labels = to_categorical(test_labels, num_classes=num_classes)\n",
        "y_true = [i.argmax() for i in test_labels]\n",
        "\n",
        "\n",
        "y_pred=yPredictions\n",
        "y_pred_probabilities=y_pred\n",
        "\n",
        "# y_pred = np.argmax(y_pred,axis = 1) \n",
        "y_actual = y_true\n",
        "\n",
        "classnames=[]\n",
        "for classname in test_generator.class_indices:\n",
        "    classnames.append(classname)\n",
        "\n",
        "confusion_mtx = confusion_matrix(y_actual, y_pred) \n",
        "print(confusion_mtx)\n",
        "target_names = classnames\n",
        "print(classification_report(y_actual, y_pred, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tZ0aKIZ1uZh"
      },
      "outputs": [],
      "source": [
        "print('roc_auc_score = ' + str(roc_auc_score(y_pred, y_true)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEw4yTSosWfW"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "print(classification_report( true_classes, yPredictions))\n",
        "cm_matrix = sklearn.metrics.confusion_matrix(true_classes, yPredictions)\n",
        "cm_matrix\n",
        "\n",
        "class_names=[0,1] # name  of classes\n",
        "fig, ax = plt.subplots()\n",
        "tick_marks = np.arange(len(class_names))\n",
        "plt.xticks(tick_marks, class_names)\n",
        "plt.yticks(tick_marks, class_names)\n",
        "# create heatmap\n",
        "sns.heatmap(pd.DataFrame(cm_matrix), annot=True,linewidths=.5, cmap=\"YlGnBu\" ,fmt='g')\n",
        "ax.xaxis.set_label_position(\"top\")\n",
        "plt.tight_layout()\n",
        "plt.title('Confusion matrix', y=1.1)\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qujx5fb0tkda"
      },
      "outputs": [],
      "source": [
        "# y_pred_proba = clf.predict_proba(X_test)[::,1]\n",
        "fpr, tpr, _ = sklearn.metrics.roc_curve(true_classes, yPredictions)\n",
        "auc = sklearn.metrics.roc_auc_score(true_classes, yPredictions)\n",
        "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.plot(fpr, tpr, color='orange', label='ROC curve from the proposed method')\n",
        "plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
        "#     plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDvx47pY1qJy"
      },
      "outputs": [],
      "source": [
        "total=sum(sum(cm))\n",
        "\n",
        "sensitivity = cm[0,0]/(cm[0,0]+cm[1,0])\n",
        "print('Sensitivity : ', sensitivity*100 )\n",
        "\n",
        "Specificity = cm[1,1]/(cm[1,1]+cm[0,1])\n",
        "print('Specificity : ', Specificity*100 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7epV5Bd1_ML"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "TEST_CNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
